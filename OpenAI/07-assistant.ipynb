{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assistants ajudam a criar assistentes especificos sobre um determinado tipo de assunto.\n",
    "Respondem assuntos complexos e especificos(com base num arquivo .csv ou .pdf por exemplo)\n",
    "Esse código é o basico para a criaçao do modelo, alimentando com as informações e obtendo o resultado\n",
    "Esse notebook é um exemplo completo de como usar a API da OpenAI para:\n",
    "Criar um assistente especializado.\n",
    "Enviar perguntas técnicas.\n",
    "Aguardar e recuperar respostas.\n",
    "Auditar os passos internos da execução.\n",
    "46. Explorando Assistants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import openai\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria um Assistant personalizado com:\n",
    "\n",
    "Nome: \"Tutor de Tecnologia\"\n",
    "Instruções: foco em tecnologia\n",
    "Ferramenta: code_interpreter\n",
    "Modelo: gpt-3.5-turbo-0125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Tutor de Tecnologia\",\n",
    "    instructions=\"Você é um tutor sobre assuntos relacionados a tecnologia\",\n",
    "    tools=[{\"type\":\"code_interpreter\"}],\n",
    "    model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pergunta = \"\"\"\n",
    "Em um sistema de cache com mapeamento direto, dado uma memória principal de uma cache\n",
    "de 256 KB e blocos de 64 bytes:\n",
    "- Quantas linhas existem na cache?\n",
    "- Onde o bloco de endereço 0x1A23C será mapeado na cache?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Criação da Thread\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=pergunta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Executa a thread\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Nome de usuário premium\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.1)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python/OpenAI/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# mostra o estagio da solicitação que voce enviou. Pode ser \"executado\", ou estar no estagio \n",
    "# de \"fila/queued\" por exemplo\n",
    "run.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aguarda a thread rodar\n",
    "while run.status in [\"queued\", \"in_progress\", \"cancelling\"]:\n",
    "    time.sleep(1)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verifica a resposta quando tivermos a resposta da thread\n",
    "if run.status == \"completed\":\n",
    "    mensagens = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id\n",
    "    )\n",
    "    print(mensagens.data[0].content[0].text.value)\n",
    "else:\n",
    "    print(f\"Erro {run.status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica se a execução foi concluída e tenta imprimir a resposta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mensagens.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analisando a logica/passos do modelo para chegar na resposta\n",
    "run_steps = client.beta.threads.run.steps.list(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime os detalhes de cada passo:\n",
    "Se o modelo usou o code_interpreter, mostra o código executado.\n",
    "Se foi uma criação de mensagem, mostra o conteúdo gerado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for step in run_steps.data[::-1]:\n",
    "    print(f\"\\n===Step {step.step_details.type}\")\n",
    "    if step.step_details.type == \"tool_calls\":\n",
    "        for tool_call in step.step_details.tool_calls:\n",
    "            print(\"-\" * 10)\n",
    "            print(tool_call.code_interpreter.input)\n",
    "            print(\"-\" * 10)\n",
    "    if step.step_details.type == \"message_creation\":\n",
    "        message = client.beta.threads.messages.retrieve(\n",
    "        thread_id=thread.id,\n",
    "        message_id=step.step_details.message_creation.message_id\n",
    "    )\n",
    "\n",
    "print(message.content[0].text.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
